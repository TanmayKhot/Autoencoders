{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "    transforms = transforms.Compose([transforms.ToTensor()])\n",
    "    train_dataset = datasets.MNIST(\n",
    "        './data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms)\n",
    "\n",
    "    test_dataset = datasets.MNIST(\n",
    "        './data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "    BATCH_SIZE = 128    \n",
    "    N_EPOCHS = 50       \n",
    "    INPUT_DIM = 784    \n",
    "    HIDDEN_DIM = 512   \n",
    "    LATENT_DIM = 2  \n",
    "    lr = 0.001           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    " class Encoder(nn.Module):\n",
    "        \n",
    "        def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "           \n",
    "            super().__init__()\n",
    "\n",
    "            self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "            self.mu = nn.Linear(hidden_dim, z_dim)\n",
    "            self.var = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # x is of shape [batch_size, input_dim]\n",
    "\n",
    "            hidden = F.relu(self.linear(x))\n",
    "            # hidden is of shape [batch_size, hidden_dim]\n",
    "            z_mu = self.mu(hidden)\n",
    "            # z_mu is of shape [batch_size, latent_dim]\n",
    "            z_var = self.var(hidden)\n",
    "            # z_var is of shape [batch_size, latent_dim]\n",
    "\n",
    "            return z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "  class Decoder(nn.Module):\n",
    "        \n",
    "        def __init__(self, z_dim, hidden_dim, output_dim):\n",
    "            \n",
    "            super().__init__()\n",
    "\n",
    "            self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "            self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # x is of shape [batch_size, latent_dim]\n",
    "\n",
    "            hidden = F.relu(self.linear(x))\n",
    "            # hidden is of shape [batch_size, hidden_dim]\n",
    "\n",
    "            predicted = torch.sigmoid(self.out(hidden))\n",
    "            # predicted is of shape [batch_size, output_dim]\n",
    "\n",
    "            return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "  class VAE(nn.Module):\n",
    "        \n",
    "        def __init__(self, enc, dec):\n",
    "            super().__init__()\n",
    "\n",
    "            self.enc = enc\n",
    "            self.dec = dec\n",
    "\n",
    "        def forward(self, x):\n",
    "            # encode\n",
    "            z_mu, z_var = self.enc(x)\n",
    "\n",
    "            std = torch.exp(z_var / 2)\n",
    "            eps = torch.randn_like(std)\n",
    "            x_sample = eps.mul(std).add_(z_mu)\n",
    "\n",
    "            # decode\n",
    "            predicted = self.dec(x_sample)\n",
    "            return predicted, z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # encoder\n",
    "    encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LATENT_DIM)\n",
    "\n",
    "    # decoder\n",
    "    decoder = Decoder(LATENT_DIM, HIDDEN_DIM, INPUT_DIM)\n",
    "\n",
    "    # vae\n",
    "    model = VAE(encoder, decoder).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    " def train():\n",
    "        # set the train mode\n",
    "        model.train()\n",
    "\n",
    "        # loss of the epoch\n",
    "        train_loss = 0\n",
    "\n",
    "        for i, (x, _) in enumerate(train_iterator):\n",
    "            # reshape the data into [batch_size, 784]\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # update the gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "            # reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "            # kl divergence loss\n",
    "            kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "            # total loss\n",
    "            loss = recon_loss + kl_loss\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "        return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def test():\n",
    "        # set the evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # test loss for the data\n",
    "        test_loss = 0\n",
    "\n",
    "        # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "        with torch.no_grad():\n",
    "            for i, (x, _) in enumerate(test_iterator):\n",
    "                # reshape the data\n",
    "                x = x.view(-1, 28 * 28)\n",
    "                x = x.to(device)\n",
    "\n",
    "                # forward pass\n",
    "                x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "                # reconstruction loss\n",
    "                recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "                \n",
    "                # kl divergence loss\n",
    "                kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "                \n",
    "                # total loss\n",
    "                loss = recon_loss + kl_loss\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    best_test_loss = float('inf')\n",
    "\n",
    "    for e in range(N_EPOCHS):\n",
    "\n",
    "        train_loss = train()\n",
    "        test_loss = test()\n",
    "\n",
    "        train_loss /= len(train_dataset)\n",
    "        test_loss /= len(test_dataset)\n",
    "\n",
    "        print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # sample and generate a image\n",
    "    z = torch.randn(1, LATENT_DIM).to(device)\n",
    "\n",
    "    # run only the decoder\n",
    "    reconstructed_img = model.dec(z)\n",
    "    img = reconstructed_img.view(28, 28).data\n",
    "\n",
    "    print(z.shape)\n",
    "    print(img.shape)\n",
    "\n",
    "    plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai_v1]",
   "language": "python",
   "name": "conda-env-fastai_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
