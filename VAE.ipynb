{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.basics import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "newdata = pd.read_csv(\"mnist_data.csv\")\n",
    "newdata\n",
    "mydata = newdata.iloc[0:1000,]\n",
    "mydata = mydata.drop([\"label\"],axis=1)\n",
    "mydata = mydata/255\n",
    "print(mydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = 784\n",
    "nn_dim = 512 #encoder\n",
    "latent_variable_dim = 2 #for mean and std dev\n",
    "\n",
    "def values(shape):\n",
    "    val = np.random.normal(scale = 1/(np.sqrt(shape[0]/2)), size = shape)\n",
    "    return (val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights\n",
      "(784, 512)\n",
      "(512, 2)\n",
      "(2, 512)\n",
      "(512, 784)\n"
     ]
    }
   ],
   "source": [
    "#Finding initail weights and biases for every layer\n",
    "weight_encoder = values([image_dim,nn_dim])\n",
    "weight_mean = values([nn_dim, latent_variable_dim])\n",
    "weight_stddev = values([nn_dim, latent_variable_dim])\n",
    "weight_decoder = values([latent_variable_dim,nn_dim])\n",
    "weight_output = values([nn_dim,image_dim])\n",
    "\n",
    "bias_encoder = values([nn_dim])\n",
    "bias_mean = values([latent_variable_dim])\n",
    "bias_stddev = values([latent_variable_dim])\n",
    "bias_decoder = values([nn_dim])\n",
    "bias_output = values([image_dim])\n",
    "\n",
    "print(\"Weights\")\n",
    "print(weight_encoder.shape)\n",
    "print(weight_mean.shape)\n",
    "print(weight_decoder.shape)\n",
    "print(weight_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "#Encoder layer\n",
    "encoder = np.add(np.dot(mydata,weight_encoder),bias_encoder)\n",
    "encoder = torch.from_numpy(encoder)\n",
    "t = nn.Tanh()\n",
    "encoder_layer = t(encoder)\n",
    "#print(encoder_layer.shape)\n",
    "#Shape [1000,512]\n",
    "\n",
    "\n",
    "#Mean and Standard deviation layer\n",
    "mean = np.add(np.dot(encoder_layer,weight_mean), bias_mean)\n",
    "mean_layer = torch.from_numpy(mean)\n",
    "stddev = np.add(np.dot(encoder_layer,weight_stddev),bias_stddev)\n",
    "stddev_layer = torch.from_numpy(stddev)\n",
    "#Shape (1000,2)\n",
    "\n",
    "\n",
    "#latent layer\n",
    "mu,sigma = 0,1\n",
    "epsilon = np.random.normal(mu, sigma, size = (1000,2))\n",
    "epsilon = torch.from_numpy(epsilon)\n",
    "latent_layer = torch.from_numpy(stddev)\n",
    "latent_layer = torch.add(mean_layer, torch.mul((torch.exp(0.5*stddev_layer)), epsilon))\n",
    "#Shape [1000,2]\n",
    "\n",
    "#Decoder layer\n",
    "lat = latent_layer.numpy()\n",
    "decoder = np.add((np.dot(lat,weight_decoder)), bias_decoder)\n",
    "decoder = torch.from_numpy(decoder)\n",
    "decoder_layer = t(decoder)\n",
    "#[100,512]\n",
    "\n",
    "#Output layer\n",
    "dec = decoder_layer.numpy()\n",
    "output = np.add(np.dot(dec,weight_output), bias_output)\n",
    "output = torch.from_numpy(output)\n",
    "output_layer = t(output)\n",
    "#[1000,784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss funxtion\n",
    "\n",
    "#Loss\n",
    "\n",
    "def loss_function(input_image, output_image):\n",
    "    dfl = input_image*math.log(1e-10+output_image) + (1-original_image)*math.log(1e-10 + 1 - output_image)\n",
    "    dfl = torch.from_numpy(dfl)\n",
    "    data_fidelity_loss = -1*torch.sum(dfl,dim =1)\n",
    "    \n",
    "    kldl = 1 + stddev_layer - np.square(mean_layer) - np.exp(stddev_layer)\n",
    "    kldl = torch.from_numpy(kldl)\n",
    "    kl_divergence_loss = -0.5*torch.sum(kldl, dim=1)\n",
    "    \n",
    "    loss = 0.5*(data_fidelity_loss + kl_divergence_loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai_v1]",
   "language": "python",
   "name": "conda-env-fastai_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
